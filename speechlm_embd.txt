Name: speech_encoder.mask_emb, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.0.0.weight, Shape: torch.Size([512, 1, 10]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.0.2.weight, Shape: torch.Size([512]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.0.2.bias, Shape: torch.Size([512]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.1.0.weight, Shape: torch.Size([512, 512, 3]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.2.0.weight, Shape: torch.Size([512, 512, 3]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.3.0.weight, Shape: torch.Size([512, 512, 3]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.4.0.weight, Shape: torch.Size([512, 512, 3]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.5.0.weight, Shape: torch.Size([512, 512, 2]), Requires Grad: False
Name: speech_encoder.feature_extractor.conv_layers.6.0.weight, Shape: torch.Size([512, 512, 2]), Requires Grad: False
Name: speech_encoder.post_extract_proj.weight, Shape: torch.Size([768, 512]), Requires Grad: False
Name: speech_encoder.post_extract_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.final_proj_list.0.weight, Shape: torch.Size([256, 768]), Requires Grad: False
Name: speech_encoder.final_proj_list.0.bias, Shape: torch.Size([256]), Requires Grad: False
Name: speech_encoder.final_proj_list.1.weight, Shape: torch.Size([256, 768]), Requires Grad: False
Name: speech_encoder.final_proj_list.1.bias, Shape: torch.Size([256]), Requires Grad: False
Name: speech_encoder.encoder.pos_conv.0.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.pos_conv.0.weight_g, Shape: torch.Size([1, 1, 128]), Requires Grad: False
Name: speech_encoder.encoder.pos_conv.0.weight_v, Shape: torch.Size([768, 48, 128]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.0.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.1.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.2.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.3.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.4.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layers.5.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.encoder.layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.encoder.pos_emb.pe_k.weight, Shape: torch.Size([320, 96]), Requires Grad: False
Name: speech_encoder.layer_norm.weight, Shape: torch.Size([512]), Requires Grad: False
Name: speech_encoder.layer_norm.bias, Shape: torch.Size([512]), Requires Grad: False
Name: speech_encoder.unit_encoder.embed_positions.weight, Shape: torch.Size([3002, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layernorm_embedding.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layernorm_embedding.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.0.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.1.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.2.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.3.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.4.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.k_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.k_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.v_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.v_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.q_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.q_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.out_proj.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn.out_proj.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.self_attn_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.fc1.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.fc1.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.fc2.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.fc2.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.final_layer_norm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.final_layer_norm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.norm_k.weight, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.layers.5.norm_k.bias, Shape: torch.Size([96]), Requires Grad: False
Name: speech_encoder.unit_encoder.pos_emb.pe_k.weight, Shape: torch.Size([320, 96]), Requires Grad: False
Name: text_encoder.embeddings.word_embeddings.weight, Shape: torch.Size([30522, 768]), Requires Grad: False
Name: text_encoder.embeddings.position_embeddings.weight, Shape: torch.Size([512, 768]), Requires Grad: False
Name: text_encoder.embeddings.token_type_embeddings.weight, Shape: torch.Size([2, 768]), Requires Grad: False
Name: text_encoder.embeddings.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.embeddings.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.0.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.0.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.0.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.1.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.1.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.1.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.2.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.2.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.2.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.3.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.3.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.3.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.4.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.4.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.4.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.5.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.5.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.5.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.6.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.6.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.6.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.7.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.7.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.7.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.8.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.8.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.8.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.9.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.9.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.9.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.10.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.10.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.10.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.self.query.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.self.query.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.self.key.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.self.key.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.self.value.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.self.value.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.output.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.attention.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.intermediate.dense.weight, Shape: torch.Size([3072, 768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.intermediate.dense.bias, Shape: torch.Size([3072]), Requires Grad: False
Name: text_encoder.encoder.layer.11.output.dense.weight, Shape: torch.Size([768, 3072]), Requires Grad: False
Name: text_encoder.encoder.layer.11.output.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.output.LayerNorm.weight, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.encoder.layer.11.output.LayerNorm.bias, Shape: torch.Size([768]), Requires Grad: False
Name: text_encoder.pooler.dense.weight, Shape: torch.Size([768, 768]), Requires Grad: False
Name: text_encoder.pooler.dense.bias, Shape: torch.Size([768]), Requires Grad: False
Name: fusion.q_proj.weight, Shape: torch.Size([256, 768]), Requires Grad: True
Name: fusion.q_proj.bias, Shape: torch.Size([256]), Requires Grad: True
Name: fusion.k_proj.weight, Shape: torch.Size([256, 768]), Requires Grad: True
Name: fusion.k_proj.bias, Shape: torch.Size([256]), Requires Grad: True
Name: fusion.v_proj.weight, Shape: torch.Size([256, 768]), Requires Grad: True
Name: fusion.v_proj.bias, Shape: torch.Size([256]), Requires Grad: True
Name: fusion.projection.0.weight, Shape: torch.Size([256, 256]), Requires Grad: True
Name: fusion.projection.0.bias, Shape: torch.Size([256]), Requires Grad: True
Name: fusion.projection.3.weight, Shape: torch.Size([1, 256]), Requires Grad: True
Name: fusion.projection.3.bias, Shape: torch.Size([1]), Requires Grad: True
Name: classifier.0.weight, Shape: torch.Size([1]), Requires Grad: True
Name: classifier.0.bias, Shape: torch.Size([1]), Requires Grad: True
Name: classifier.1.weight, Shape: torch.Size([512, 1]), Requires Grad: True
Name: classifier.1.bias, Shape: torch.Size([512]), Requires Grad: True
Name: classifier.4.weight, Shape: torch.Size([512]), Requires Grad: True
Name: classifier.4.bias, Shape: torch.Size([512]), Requires Grad: True
Name: classifier.5.weight, Shape: torch.Size([256, 512]), Requires Grad: True
Name: classifier.5.bias, Shape: torch.Size([256]), Requires Grad: True
Name: classifier.8.weight, Shape: torch.Size([5, 256]), Requires Grad: True
Name: classifier.8.bias, Shape: torch.Size([5]), Requires Grad: True